{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import json\n",
    "from itertools import tee\n",
    "from tqdm import trange\n",
    "from board import Board\n",
    "from player import Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over a list pairwise\n",
    "def pairwise(iterable):\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player parameters\n",
    "alpha = 0.5   # learning rate\n",
    "\n",
    "board = Board()\n",
    "player = Player(alpha)\n",
    "# player.load_policy(\"params/values_10M_training.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000000/10000000 [32:16<00:00, 5164.22it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Player' object has no attribute 'save_policy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ec12c33e53bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# save player's policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"params/values.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Player' object has no attribute 'save_policy'"
     ]
    }
   ],
   "source": [
    "# number of training matches\n",
    "num_train = 10000000\n",
    "\n",
    "for n in trange(num_train):\n",
    "    # reset board for new game\n",
    "    board.reset()\n",
    "    # store the board states to backpropagate value when game ends\n",
    "    board_states = []\n",
    "    \n",
    "    # 1/2 of the time o-player plays first\n",
    "    if random.random() < 0.5:\n",
    "        # o-player starts in random location\n",
    "        board.add_o(random.choice([i for i in range(9)]))\n",
    "        \n",
    "    # continue playing until board is full or someone won\n",
    "    while not board.is_full():\n",
    "        # x-player chooses an action\n",
    "        action = player.choose_action(board.get_state())\n",
    "        # update board\n",
    "        board.add_x(action)\n",
    "        # store board state for training later\n",
    "        board_states.append(board.get_state())\n",
    "        # check if player won\n",
    "        if player.has_won(board.get_state()): break\n",
    "        # if nobody won yet, inverse the board\n",
    "        board.inverse()\n",
    "\n",
    "    # backpropagate value of game to update the policy\n",
    "    board_states.reverse()\n",
    "    for state_k, state_km1 in pairwise(board_states):\n",
    "        player.update_values(state_km1, state_k)\n",
    "    \n",
    "    # reduce learning rate every 10000 matches\n",
    "    if n % 100000 == 0:\n",
    "        player.reduce_alpha()\n",
    "    # player.set_alpha(1/(n+1))\n",
    "        \n",
    "# save player's policy\n",
    "player.save_values(\"params/values.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6597808029835397"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.states.get(\"----x----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if the player learned the optimal strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished testing\n",
      "   number of draws :  4  of  4\n"
     ]
    }
   ],
   "source": [
    "# no random actions anymore\n",
    "player.playing_mode()\n",
    "# player.load_policy(\"params/values_10M_training.json\")\n",
    "\n",
    "o_indices = [0,2,6,8]\n",
    "# number of testing matches\n",
    "num_test = len(o_indices)\n",
    "# number of matches that finished in a draw\n",
    "num_draw = 0\n",
    "\n",
    "for o_idx in o_indices:\n",
    "    # reset board for new game\n",
    "    board.reset()\n",
    "    # o-player starts in corner location\n",
    "    board.add_o(o_idx)\n",
    "\n",
    "    is_draw = True\n",
    "    while not board.is_full():\n",
    "        # player 'x' plays\n",
    "        action = player.choose_action(board.get_state())\n",
    "        # update board\n",
    "        board.add_x(action)\n",
    "        # check if player won\n",
    "        if player.has_won(board.get_state()): \n",
    "            is_draw = False\n",
    "            break\n",
    "        # if nobody won yet, inverse the board\n",
    "        board.inverse()\n",
    "\n",
    "    if is_draw:\n",
    "        num_draw += 1\n",
    "\n",
    "print(\"Finished testing\")\n",
    "print('   number of draws : ', num_draw, \" of \", num_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play against it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "board.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['o', 'x', 'x']\n",
      "['x', 'o', 'o']\n",
      "['-', 'o', 'x']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "o_idx = 7    # None or index\n",
    "\n",
    "# reset board for new game\n",
    "if board.is_full():\n",
    "    board.reset()\n",
    "\n",
    "# o-player starts in random corner location\n",
    "board.add_o(o_idx)\n",
    "\n",
    "if not board.is_full():\n",
    "    # player 'x' plays\n",
    "    action = player.choose_action(board.get_state())\n",
    "\n",
    "    # update board\n",
    "    board.add_x(action)\n",
    "\n",
    "board.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.799192918181171e-06\n"
     ]
    }
   ],
   "source": [
    "print(player.states.get('oxoxox---'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8361312809238517\n"
     ]
    }
   ],
   "source": [
    "print(player.states.get('xoxoxo---'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
